%!TEX root = gpu-vendor-model-matrix.tex
\begin{frame}
\relsize{-2}\vspace*{-1\baselineskip}
\begin{multicols}{3}
    \begin{description}[Fortran]
    \ifdefined\tightlist\tightlist\fi%
        \item[\fullok] Full vendor support
        \item[\prettyok] Vendor support, but not (yet) entirely comprehensive
        \item[\indirectok] Indirect, but comprehensive support, by vendor
        \item[\nonvendorok] Comprehensive support, but not by vendor
        \item[\somesupport] Limited, probably indirect support -- but at least some
        \item[\nope] No direct support available, but of course one could ISO-C-bind your way through it or directly link the libraries
        \item[\C] C++ (sometimes also C)
        \item[\F] Fortran
        \end{description}
\end{multicols}

\begin{tabular}{c|cc|cc|cc|cc|cc|cc|cc|cc|c}
  &
        \multicolumn{2}{c}{CUDA} &
        \multicolumn{2}{c}{HIP} &
        \multicolumn{2}{c}{SYCL} &
        \multicolumn{2}{c}{OpenACC} &
        \multicolumn{2}{c}{OpenMP} &
        \multicolumn{2}{c}{Standard} &
        \multicolumn{2}{c}{Kokkos} &
        \multicolumn{2}{c}{ALPAKA} &
        \\
  &
        \C &\F &
        \C &\F &
        \C &\F &
        \C &\F &
        \C &\F &
        \C &\F &
        \C &\F &
        \C &\F &
        \Python 
        \\
  NVIDIA &
  \fullok\refwithstate{cudac} & \fullok\refwithstate{cudafortran} & \indirectok\refwithstate{nvidiahip} & \nonvendorok\refwithstate{hipfortran} & \nonvendorok\refwithstate{nvidiasycl} & \nope\refwithstate{syclfortran} & \fullok\refwithstate{openaccc} & \fullok\refwithstate{openaccfortran} & \prettyok\fullok\refwithstate{nvidiaopenmpc} & \prettyok\fullok\refwithstate{nvidiaopenmpfortran} & \fullok\refwithstate{nvidiastandardc} & \fullok\refwithstate{nvidiastandardfortran} & \nonvendorok\refwithstate{nvidiakokkosc} & \somesupport\refwithstate{nvidiakokkosfortran} & \nonvendorok\refwithstate{nvidiaalpakac} & \nope\refwithstate{nvidiaalpakafortran} & \prettyok\nonvendorok\refwithstate{nvidiapython} \\
  AMD &
  \indirectok\refwithstate{amdcudac} & \somesupport\refwithstate{amdcudafortran} & \fullok\refwithstate{amdhipc} & \nope\refwithstate{hipfortran} & \indirectok\refwithstate{amdsyclc} & \nope\refwithstate{syclfortran} & \nonvendorok\refwithstate{amdopenaccc} & \nonvendorok\somesupport\refwithstate{amdopenaccfortran} & \fullok\refwithstate{amdopenmp} & \fullok\refwithstate{amdopenmp} & \nope\refwithstate{amdstandard} & \nope\refwithstate{amdstandard} & \nonvendorok\refwithstate{amdkokkosc} & \somesupport\refwithstate{nvidiakokkosfortran} & \nonvendorok\refwithstate{amdalpakac} & \nope\refwithstate{nvidiaalpakafortran} & \somesupport\refwithstate{amdpython} \\
  Intel &
  \indirectok\refwithstate{intelcudac} & \nope\refwithstate{intelcudafortran} & \somesupport\refwithstate{intelhipc} & \nope\refwithstate{hipfortran} & \fullok\refwithstate{intelsyclc} & \nope\refwithstate{syclfortran} & \somesupport\refwithstate{intelopenacc} & \somesupport\refwithstate{intelopenacc} & \fullok\refwithstate{intelopenmp} & \fullok\refwithstate{intelopenmp} & \nope\refwithstate{prettyok} & \prettyok\refwithstate{intelstandardfortran} & \nonvendorok\refwithstate{intelkokkosc} & \somesupport\refwithstate{nvidiakokkosfortran} & \somesupport\refwithstate{intelalpakac} & \nope\refwithstate{nvidiaalpakafortran} & \somesupport\refwithstate{intelpython} \\
  \end{tabular}
\end{frame}

\begin{frame}[allowframebreaks]
\begin{itemize}
    \relsize{-2}%
    \ifdefined\tightlist\tightlist\fi%
        \item \ref{cudac}: CUDA C/C++ is supported on NVIDIA GPUs through the \href{https://developer.nvidia.com/cuda-toolkit}{CUDA Toolkit}
        \item \ref{cudafortran}: CUDA Fortran, a proprietary Fortran extension, is supported on NVIDIA GPUs via the \href{https://developer.nvidia.com/hpc-sdk}{NVIDIA HPC SDK}
        \item \ref{nvidiahip}: \href{https://github.com/ROCm-Developer-Tools/HIP}{HIP} programs can directly use NVIDIA GPUs via a CUDA backend; HIP is maintained by AMD
        \item \ref{hipfortran}: No such thing like HIP for Fortran
        \item \ref{nvidiasycl}: SYCL can be used on NVIDIA GPUs with \emph{experimental} support either in \href{https://github.com/codeplaysoftware/sycl-for-cuda/blob/cuda/sycl/doc/GetStartedWithSYCLCompiler.md\#build-sycl-toolchain-with-support-for-nvidia-cuda}{SYCL} directly or in \href{https://github.com/intel/llvm/blob/sycl/sycl/doc/GetStartedGuide.md\#build-dpc-toolchain-with-support-for-nvidia-cuda}{DPC++}, or via \href{https://github.com/illuhad/hipSYCL}{hipSYCL}
        \item \ref{syclfortran}: No such thing like SYCL for Fortran
        \item \ref{openaccc}: OpenACC C/C++ supported on NVIDIA GPUs directly (and best) through NVIDIA HPC SDK; additional, somewhat limited support by \href{https://gcc.gnu.org/wiki/OpenACC}{GCC C compiler} and in LLVM through \href{https://csmd.ornl.gov/project/clacc}{Clacc}
        \item \ref{openaccfortran}: OpenACC Fortran supported on NVIDIA GPUs directly (and best) through NVIDIA HPC SDK; additional, somewhat limited support by GCC Fortran compiler and \href{https://ieeexplore.ieee.org/document/9651310}{Flacc}
        \item \ref{nvidiaopenmpc}: OpenMP in C++ supported on NVIDIA GPUs through NVIDIA HPC SDK (albeit \href{https://docs.nvidia.com/hpc-sdk/compilers/hpc-compilers-user-guide/index.html\#openmp-use}{with a few limits}), by GCC, and Clang; see \href{https://www.openmp.org/wp-content/uploads/2022_ECP_Community_BoF_Days-OpenMP_RoadMap_BoF.pdf}{OpenMP ECP BoF on status in 2022}.
        \item \ref{nvidiaopenmpfortran}: OpenMP in Fortran supported on NVIDIA GPUs through NVIDIA HPC SDK (but not full OpenMP feature set available), by GCC, and Flang
        \item \ref{nvidiastandardc}: pSTL features supported on NVIDIA GPUs through \href{https://docs.nvidia.com/hpc-sdk/compilers/c++-parallel-algorithms/}{NVIDIA HPC SDK}
        \item \ref{nvidiastandardfortran}: Standard Language parallel features supported on NVIDIA GPUs through NVIDIA HPC SDK
        \item \ref{nvidiakokkosc}: \href{https://github.com/kokkos/kokkos}{Kokkos} supports NVIDIA GPUs by calling CUDA as part of the compilation process
        \item \ref{nvidiakokkosfortran}: Kokkos is a C++ model, but an official compatibility layer (\href{https://github.com/kokkos/kokkos-fortran-interop}{\emph{Fortran Language Compatibility Layer}, FLCL}) is available.
        \item \ref{nvidiaalpakac}: \href{https://github.com/alpaka-group/alpaka}{Alpaka} supports NVIDIA GPUs by calling CUDA as part of the compilation process
        \item \ref{nvidiaalpakafortran}: Alpaka is a C++ model
        \item \ref{nvidiapython}: There is a vast community of offloading Python code to NVIDIA GPUs, like \href{https://cupy.dev/}{CuPy}, \href{https://numba.pydata.org/}{Numba}, \href{https://developer.nvidia.com/cunumeric}{cuNumeric}, and many others; NVIDIA actively supports a lot of them, but has no direct product like \emph{CUDA for Python}; so, the status is somewhere in between
        \item \ref{amdcudac}: \href{https://github.com/ROCm-Developer-Tools/HIPIFY}{hipify} by AMD can translate CUDA calls to HIP calls which runs natively on AMD GPUs
        \item \ref{amdcudafortran}: AMD offers a Source-to-Source translator to convert some CUDA Fortran functionality to OpenMP for AMD GPUs (\href{https://github.com/ROCmSoftwarePlatform/gpufort}{gpufort}); in addition, there are ROCm library bindings for Fortran in \href{https://github.com/ROCmSoftwarePlatform/hipfort}{hipfort} OpenACC/CUDA Fortran Source-to-Source translator
        \item \ref{amdhipc}: \href{https://github.com/ROCm-Developer-Tools/HIP}{HIP} is the preferred native programming model for AMD GPUs
        \item \ref{amdsyclc}: SYCL can use AMD GPUs, for example with \href{https://github.com/illuhad/hipSYCL}{hipSYCL} or \href{https://github.com/intel/llvm/blob/sycl/sycl/doc/GetStartedGuide.md\#build-dpc-toolchain-with-support-for-hip-amd}{DPC++ for HIP AMD}
        \item \ref{amdopenaccc}: OpenACC C/C++ can be used on AMD GPUs via GCC or Clacc; also, \href{https://github.com/intel/intel-application-migration-tool-for-openacc-to-openmp}{Intel\textquotesingle s OpenACC to OpenMP Source-to-Source translator} can be used to generate OpenMP directives from OpenACC directives
        \item \ref{amdopenaccfortran}: OpenACC Fortran can be used on AMD GPUs via GCC; also, AMD\textquotesingle s \href{https://github.com/intel/intel-application-migration-tool-for-openacc-to-openmp}{gpufort} Source-to-Source translator can move OpenACC Fortran code to OpenMP Fortran code, and also Intel\textquotesingle s translator can work
        \item \ref{amdopenmp}: AMD offers a dedicated, Clang-based compiler for using OpenMP on AMD GPUs: \href{https://github.com/ROCm-Developer-Tools/aomp}{AOMP}; it supports both C/C++ (Clang) and Fortran (Flang, \href{https://github.com/ROCm-Developer-Tools/aomp/tree/aomp-dev/examples/fortran/simple_offload}{example})
        \item \ref{amdstandard}: Currently, no (known) way to launch Standard-based parallel algorithms on AMD GPUs
        \item \ref{amdkokkosc}: Kokkos supports AMD GPUs through HIP
        \item \ref{amdalpakac}: Alpaka supports AMD GPUs through HIP
        \item \ref{amdpython}: AMD does not officially support GPU programming with Python (also not semi-officially like NVIDIA), but third-party support is available, for example through \href{https://numba.pydata.org/numba-doc/latest/roc/index.html}{Numba} (currently inactive) or a \href{https://docs.cupy.dev/en/latest/install.html?highlight=rocm\#building-cupy-for-rocm-from-source}{HIP version of CuPy}
        \item \ref{intelcudac}: \href{https://github.com/oneapi-src/SYCLomatic}{SYCLomatic} translates CUDA code to SYCL code, allowing it to run on Intel GPUs; also, Intel\textquotesingle s \href{https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compatibility-tool.html}{DPC++ Compatibility Tool} can transform CUDA to SYCL
        \item \ref{intelcudafortran}: No direct support, only via ISO C bindings, but at least an example can be \href{https://github.com/codeplaysoftware/SYCL-For-CUDA-Examples/tree/master/examples/fortran_interface}{found on GitHub}; it\textquotesingle s pretty scarce and not by Intel itself, though
        \item \ref{intelhipc}: \href{https://github.com/CHIP-SPV/chip-spv}{CHIP-SPV} supports mapping CUDA and HIP to OpenCL and Intel\textquotesingle s Level Zero, making it run on Intel GPUs
        \item \ref{intelsyclc}: \href{https://www.khronos.org/sycl/}{SYCL} is the prime programming model for Intel GPUs; actually, SYCL is only a standard, while Intel\textquotesingle s implementation of it is called \href{https://www.intel.com/content/www/us/en/developer/tools/oneapi/data-parallel-c-plus-plus.html}{DPC++} (\emph{Data Parallel C++}), which extends the SYCL standard in various places; actually actually, Intel namespaces everything \emph{oneAPI} these days, so the \emph{full} proper name is Intel oneAPI DPC++ (which incorporates a C++ compiler and also a library)
        \item \ref{intelopenacc}: OpenACC can be used on Intel GPUs by translating the code to OpenMP with \href{https://github.com/intel/intel-application-migration-tool-for-openacc-to-openmp}{Intel\textquotesingle s Source-to-Source translator}
        \item \ref{intelopenmp}: Intel has \href{https://www.intel.com/content/www/us/en/develop/documentation/get-started-with-cpp-fortran-compiler-openmp/top.html}{extensive support for OpenMP} through their latest compilers
        \item \ref{prettyok}: Intel supports pSTL algorithms through their \href{https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-library.html\#gs.fifrh5}{DPC++ Library} (oneDPL; \href{https://github.com/oneapi-src/oneDPL}{GitHub}). It\textquotesingle s heavily namespaced and not yet on the same level as NVIDIA
        \item \ref{intelstandardfortran}: With \href{https://www.intel.com/content/www/us/en/developer/articles/release-notes/fortran-compiler-release-notes.html}{Intel oneAPI 2022.3}, Intel supports DO CONCURRENT with GPU offloading
        \item \ref{intelkokkosc}: Kokkos supports Intel GPUs through SYCL
        \item \ref{intelalpakac}: \href{https://github.com/alpaka-group/alpaka/releases/tag/0.9.0}{Alpaka v0.9.0} introduces experimental SYCL support
        \item \ref{intelpython}: Not a lot of support available at the moment, but notably \href{https://intelpython.github.io/dpnp/}{DPNP}, a SYCL-based drop-in replacement for Numpy, and \href{https://github.com/IntelPython/numba-dpex}{numba-dpex}, an extension of Numba for DPC++.
    \end{itemize}
\end{frame}